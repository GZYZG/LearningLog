存储在 HDFS 中的文件是如何被 MapReduce 处理的？存储在 HDFS 中的文件会被分为一个一个的块 (block) , 分散存储在 datanode 中. 注意此处的快并不是磁盘中的数据块, 磁盘中的数据块是磁盘进行读写的最小单位, 磁盘的块大小一般是几百字节. 文件系统是构建在磁盘之上的 (可以构建于一块磁盘, 也可以构建于多块磁盘) , 文件系统 (FS) 中也存在块的概念, 通常 FS 中的块大小是磁盘块的倍数, FS 通过文件系统的块来管理磁盘, 存储在一个文件系统中的文件会被分成多个文件系统的块来存储. HDFS 作为一个分布式的文件系统, 其实也是一个文件系统, 因此其也有块的概念. HDFS 中的块一般是 128MB. 一个文件存储进 HDFS 时会被分成多个 block, block 就是 HDFS 的存储单元. InputSplit 是一个逻辑概念, 并没有对实际文件进行切分, 它只包含一些元数据信息, 比如数据的起始位置, 数据长度, 数据所在的节点等. 它的划分方法完全取决于用户自己. 但是需要注意的是 InputSplit 的多少决定了 Map Task 的数目, 因为每个 InputSplit 会交由一个 Map Task 处理. 当MapReduce作业客户端计算 InputSplit 时, 它会计算出块中第一个记录的开始位置和最后一个记录的结束位置. 在最后一个记录不完整的情况下, InputSplit 包括下一个块的位置信息和完成该记录所需的数据的字节偏移. 