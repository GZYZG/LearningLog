\subsection{Introduction}
在搜索或推荐领域, 准确率通常是我们想到的第一个目标, 但真的是这样吗? 说到底, 各个平台的最终目的是为提供令用户更满意的服务, 为平台留住用户, 创造更多的利益. 为达成这些目的, 准确率够吗?

就视频推荐而言, 以单个目标作为优化对象的问题:
\begin{myitemize}
	\item 目标偏差: 点赞, 分享表达的满意度比播放更高;
	
	\item 物品偏差: 不同视频的播放时长体现的满意度不一致;
	
	\item 用户偏差: 有的用户偏向于点赞, 而有的偏向于收藏.
\end{myitemize}

选择哪个目标来进行优化才能满足我们的要求呢? 一个比较直接的方式就是同时优化所有的目标: 1) 单目标难以直接衡量用户满意度, 多目标优化可以最大限度地利用丰富的隐式反馈数据建模用户满意度; 2) 推荐系统排序模块要求低时延, 多目标优化训练一个模型可以预测多个目标, 线上融合多目标的预测结果进行排序.


多目标任务的常用模型: 
\begin{myitemize}
	\item Shared-Bottom;
	\item One-gate MOE(Mixture-of-Experts);
	\item MMOE, KDD'2018;
	\item ESMM, SIGIR'2018;
	\item SNR(Subnetwork Routing), AAAI'2019;
	\item PLE, RecSys'2020;
\end{myitemize}

多任务学习通常通过 Hard 或 Soft 参数共享来完成: 
\begin{myitemize}
	\item 共享 Hard 参数是神经网络 MTL 最常用的方法, 可以追溯 1993 年 Caruana 所发表的论文. 在实际应用中, 通常通过在所有任务之间共享隐藏层, 同时保留几个特定任务的输出层来实现. 共享Hard 参数大大降低了过拟合的风险. 1997 年 Jonathan Baxter 在他的论文中证明过拟合共享参数的风险为 O(N)——其中 N 是任务数——小于过拟合特定任务参数, 即输出层. 这很直观: \textbf{同时学习的任务越多, 模型找到一个含有所有任务的表征就越困难, 而过拟合原始任务的可能性就越小};
	
	\item 另一方面, 在共享 Soft 参数时, 每个任务都有自己的参数和模型. 模型参数之间的距离是正则化的, 以便鼓励参数相似化. 1998 年 Caruana 对早期的 MTL 的研究进行了总结, 并演示了三个领域中的多任务学习. 他们解释了多任务学习的工作原理, 提出了一个基于案例的方法 (如 kNN 和核回归) 的多任务学习算法和结果, 并为决策树中的多任务学习绘制了一个算法. 目前大部分MTL学习所基于的机制仍然来源于此篇文章.
\end{myitemize}
 

MTL 通常受到数据分布以及任务之间相关性的影响 (\textbf{如何衡量任务之间的相关性、关系}) . 

\subsection{多目标任务的技巧}
\subsubsection{样本加权}
在优化主目标的同时, 将其他目标转化为样本权重, 借此来达到优化其他目标的效果. 例如主目标为 CTR, 同时还有一个目标是停留时长. 则可以给停留时长长的样本赋予更高的权重. 

\textbf{特点}: 这种方式模型简单, 上线容易, 仅在训练时通过梯度乘以权重实现对其他目标的加权即可. 但本质上不是多目标建模, 而是将多个目标转化为一个目标, 目标的加权权重需要根据线上 A/B 测试才能确定. 而且, 可能不适用于多个从目标的情况, 因为将多个从目标转化为样本权重很难找到一个合适的平衡. 

\subsubsection{模型融合}
多目标模型融合, 通过将一个模型同时训练多个目标 (label 的构造) . 该方法的优点是各个任务之间能够共享信息, 同意迭代方便, 节省资源. 缺点: 目标越多模型越复杂, 各个任务之间相互影响, 迭代速度慢. 

\subsection{Shared-Bottom}
简称为 SB, 即多个任务之间有一个共享的底座. 

\subsection{MMOE}
gating network 可以用来学习任务之间的关系. 

\subsection{ESMM}
转化率预估(CVR)目前主要存在两个难点: 
- SSB(sample selection bias). CVR 预估模型是在点击的样本上进行训练的, 但是被用于在整个样本空间上进行推断. 这样做实际上存在一个很严重的问题, 因为模型用于训练的数据全是点击数据, 而上线预测则是用于全部的数据, 训练和预测的数据分布完全不一样；
- Data Sparsity. 实际上CTR预估的数据就已经非常稀疏了, 再考虑到从点击到转化, 实际转化率一般也不超过百分之几, 这样实际上用户看到一件商品, 到最后购买, 这个几率可能就只有万分之几, 一般的方法是很难去处理如此稀疏的数据的；

ESMM(Entire Space Multi-Task Model) 的创新点主要是用到了一个 multi-task learning 的方法,  并没有直接去预估CVR, 而是采用两个辅助的任务, 通过预测 CTR 和 CTCVR 来间接的预测 CVR, 因为 $CTCVR=CTR * CVR$, 这样由于 CTR 和 CTCVR 预估都是在全样本空间进行预估的, 从而避免了上面说的两个问题,  注意, 实际处理时, CVR 不是通过 CTCVR/CTR 来进行计算的, 实际上我们在模型处理是, 这三个变量都有预测, 但是只计算了 CTR 和 CVCTR 的 loss. 

