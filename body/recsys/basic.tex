\subsection{历史背景}
\paragraph{Motivation}互联网的发展，人们接受的信息越来越多，从信息稀缺时代逐渐过渡到了信息爆炸时代。面对数据的海洋，我们越来越希望我们感兴趣的信息能够直接呈现在我们面前。\tbc{red}{把用户想要的信息推荐给用户} --- 推荐系统的宗旨。

\paragraph{发展过程}：
\begin{itemize}
	\item 1994年，明尼苏达大学GroupLens研究组推出第一个自动化推荐系统GroupLens，提出将协同过滤作为推荐系统的重要技术
	\item 1995年，卡耐基梅隆大学的Robert Armstrong等人提出个性化导航系统Web Watcher；斯坦福大学的Marko Balabanovic等人退出了个性化推荐系统LIRA
	\item 1997年，Resnick等人首次提出Recommender System一词
 	\item 1998年，Amazon上线了基于物品的协同过滤算法，并在千万级用户和百万计商品的规模上进行了应用。Amazon于2003年发表论文\cite{linden2003amazon.com}公布了基于物品的协同过滤算法
	\item 2001年，IBM在其电子商务平台Websphere中增加个性化功能
	\item 2003年，Google开创AdWords盈利模式，通过用户的广告词来提供相关的广告。2007年Google为AdWords添加个性化元素，通过对用户一段时间内的搜索历史进行记录和分析，以便更精准呈现广告
	\item 2006年，Netflix宣布一项竞赛，任何人只要能将其现有的电影推荐算法Cinematch的预测准确度提高10\%就能获得100万美金
	\item 2007年，Yahoo提出SmartAds广告方案，通过分析用户信息以及用户搜索、浏览行为为用户呈现个性化广告
	\item 2007年，第一届ACM推荐系统大会举行
	\item 2015年，Facebook在其官网公布了其推荐系统原理、性能及使用情况（\href{https://engineering.fb.com/2015/06/02/core-data/recommending-items-to-more-than-a-billion-people/}{Recommending items to more than a billion people}），相关论文\cite{he2014practical}
	\item 2016年，YouTube发表论文\cite{covington2016deep}介绍Youtube如何向用户推荐个性化的视频
	\item 2016年。，Google发表论文\cite{cheng2016wide}介绍App商店中的推荐系统，即Wide\&Deep 模型
\end{itemize}

形式上来看，推荐系统的任务是这样的：给定一个输入，从数据集中搜索出一系列数据对象，并排序后输出。

输入通常是关于某个用户的表示，可以是该用户的特征、向量化的表征等，除此之外用户的行为数据，如用户的浏览记录、搜索记录、与商品的交互数据、用户的一些动态变化的数据等都可以与用户特征一起作为输入，而待搜索的数据集中通常是商品的数据，如商品的特征等，基于以上丰富的信息，将输入的信息与数据集中对象进行匹配，给出推荐的顺序。

乍一看，这和搜索很像。其实这么说也没错，都是一个\tbc{red}{Learning To Rank}的任务。其实很多领域研究的问题都很相似，通过进一步的抽象可以看作是同一个问题。但随着研究的深入，为了在一个问题上取得更好的效果，会相应地结合该领域地特点，如领域内特有的信息、领域内特有的数据形式等。因此，虽然问题之间有重叠，但为了做得更好，除了基础的方法，还需要更深入地挖掘领域地特点！例如，在推荐系统中，用户的需求和兴趣是隐含的（隐含在历史数据中，可能用户都不知道自己喜欢什么），而搜索中搜索语句是显式的（用户需求是明确的）。

\paragraph{推荐系统主要元素}
\begin{itemize}
	\item 物品集合：被推荐的物品或内容
	\item 用户：用户的基本信息，如基本信息、行为信息、兴趣爱好等
	\item 场景：用户所处的环境，如网络环境、所处位置等
	\item 推荐引擎：根据用户对物品的偏好与用户的画像数据进行拟合，学习什么样的用户会喜欢什么样的物品。引擎包含以下重要模块：
	\begin{itemize}
		\item 召回模块：根据用户和场景特征，从整个物品数据集（上百万物品）中挑选用户可能感兴趣的物品，\textbf{挑选出一个较小的候选集}（几百至几千）。召回模块中，通常使用简单的特征进行快速查询，比如用户最近点击的物品的相似物品、根据用户兴趣召回物品等。常用的算法：Word2vec、LDA、LSTM、ItemCF、UserCF、DNN等
		\item 排序模块：针对召回模块找到的\textbf{候选集进行精排}，得到用户对候选物品集的评分。常用的算法：LR、FM、XGBoost、GBDT+LR、Wide\&Deep、FNN、PNN、DeepFM、NFM、DIN等
		\item 后排模块：得到用户对候选集的评分后，可以根据一些规则对排序进行调整，如运营干预、优先级调权等
	\end{itemize}
	\item 推荐结果集：推荐结果，或推荐结果的有序排列
\end{itemize}

\subsection{会话推荐}
会话推荐 (session-based recommendation) 是预测用户在一条交互序列中可能会喜欢的下一个商品. 基于深度学习的会话推荐方法试图从用户的历史交互序列中学习和理解用户的行为, 建模用户的偏好. Session-based Recommender System (SBRS) 是指在用户未登录状态下, 仅仅依赖匿名会话进行用户下一个行为预测的一种算法, 在许多领域(如电商、短视频、直播等)有着重要的作用. SBRS 从用户与系统交互过程中的会话来学习用户的偏好. 每一个会话由一段连续的时间内用户与物品的若干个交互组成，例如在一次网购中所购买的商品.

近期 SBRS 的 SOTA 结果都是基于神经网络模型取得的. 
\begin{myitemize}
	\item 2016年提出的 GRU4Rec 是该系列中经典的一篇, 首次利用RNN对session序列建模, 相比传统的 KNN 和矩阵分解，效果有明显的提升. GRU4Rec 的核心思想是在一个 session 中，用户点击一系列 item 的行为看做一个序列，用来训练 RNN 模型。预测阶段，给定已知的点击序列作为输入，预测下一个可能点击的 item.;
	
	\item 在 GRU4Rec 的基础上, NARM 将注意力机制应用于对 session 的顺序行为及主要意图进行分别建模. 和以往方法不同的是显示地对用户在 session 目的进行建模;
	
	\item 与 NARM 相似, STAMP 利用简单的多层感知机和注意力网络对 session 内长短期兴趣分别表征. STAMP 设计了不同结构分别对 session 内长期兴趣和短期兴趣建模, 取序列中最后一个交互的item表征短期兴趣;
	
	\item 之前序列模型都仅对连续交互相邻 item 之间的序列过渡关系进行挖掘, 而忽略了不相邻 item 之间复杂地转变, SR-GNN 通过引入 GNN 来对 session graph 进行建模, 以此发掘序列内 item 之间复杂的过渡模式;
	
	\item 之前的方法通常忽略了 session 间的关系, GCE-GNN 提出了一种全局上下文增强(global-context enhanced)的 GNN 网络. 能够从两种层次来学习物品的表征，包括 global-level: 从所有 session 构成的图上进行全局的表征；以及 session-level: 从单个 session 局部 item 转移图上进行局部的表征. 最后融合二者, 并通过注意力机制形成最终的序列表征, 用于序列推荐任务.
\end{myitemize}

\subsection{共现矩阵}
显然，共现矩阵是一种矩阵，\textbf{关键是它描述了一种什么事实}？$M, N(|M| = m, |N| = 2)$表示两个相同或者不同的集合，共现矩阵可以用于表达两个集合笛卡尔乘积的元素对的某种关系，$(m_i, n_j)$间的这种关系可以用共现矩阵的元素$CM_{ij}$表示。

在具体的应用场景中，
\begin{itemize}
	\item 推荐系统：$M$表示用户集，$N$表示商品集，$CM_{ij}$表示用户$m_i$对$n_j$的喜爱程度（如评分）、是否点赞、是否分享等
	\item 自然语言处理：$M = N$表示词汇表，$CM_{ij}$表示词$m_i$与词$m_j$出现在同一个句子中的次数
	\item 社交网络：$M=N$表示作者集合，$CM_{ij}$表示$m_i$与$m_j$间存在某种关系，如朋友关系、合作关系等
\end{itemize}
共现矩阵是两个集合的元素间关系的一个很直白的表达。正是因为直白，共现矩阵通常很稀疏，空间需求大。

\subsection{召回方法分类}
召回即从海量的数据集中找出尽可能包含真实结果的候选集。常见的分类：
\begin{itemize}
	\item 行为相似召回：通过用户与物品的交互行为，发现行为指向的物品的相似物品
	\item 相似用户召回：通过用户画像和用户行为等，计算用户之间的相似性，根据相似用户的行为进行召回物品
	\item 内容相似召回：通过对物品内容进行分析，得到物品之间的相似性，根据与用户产生交互的物品来召回
\end{itemize}


\subsection{常用相似度计算方法}
\paragraph{同现相似度}
物品A和物品B的同现相似度：
$$
w_{A,B} = \frac{|N(A) \cap N(B)|}{|N(A)|}
$$
其中，$A(A), N(B)$分别表示喜欢A和B的用户集合。但是这种相似度有个问题，当B是热门物品时，喜欢A的用户中可能绝大部分也会喜欢B，那么$w_{A,B}$就会接近于1，即任何物品与热门物品的相似度都会接近于1。除此之外，还有个问题，这个相似度不是对称的，即$w_{A,B} \neg w_{B,A}$，这看起来是有点不合理的，因此，其改进如下：
$$
w_{A,B} = \frac{|N(A) \cap N(B)|}{\sqrt{|N(A)| \cdot |N(B)|}}
$$

\paragraph{欧几里得距离}
众所周知，欧氏距离是欧氏空间中两点之间的距离。两个物品A，B的向量表示为$\boldsymbol{V}_A, \boldsymbol{V}_B$，则欧式距离为：
$$
d(A, B) = ||\boldsymbol{V}_A - \boldsymbol{V}_B||_2
$$
以欧式距离计算A，B间相似性时可如下计算：
$$
sim(A, B) = \frac{1}{1 + d(A, B)}
$$
或许还有其他的形式，例如：
$$
sim(A, B) = e^{-d(A, B)}
$$

\paragraph{皮尔逊相关系数}
介于-1和1之间，它度量两个序列（可以是用户对物品的偏好/评分序列）之间的线性相关程度。它度量数字一起按比例改变的倾向性，也就是说两个数列中的数字存在一个大致的线性关系。当该倾向性强时，相关值趋于1。当相关性很弱时，相关值趋于0。在负相关的情况下一个序列的值很高而另一个序列的值低---相关趋势趋于-1。

使用皮尔逊相关系数计算用户/物品相似度时，通常取共现矩阵中的行（用户对各个物品的偏好）或列（各个用户对一个物品的偏好）作为数列来计算皮尔逊相关系数。两个物品/用户A，B的向量表示为$\boldsymbol{x}, \boldsymbol{y}$，则皮尔逊相关系数为：
$$
r_{\boldsymbol{xy}} = \frac{\sum_i (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_i (x_i - \bar{x})^2} \sqrt{\sum_i (y_i - \bar{y})^2}}
$$
其实，仔细一看，皮尔逊相关系数和余弦相似度很像，对$\boldsymbol{x}, \boldsymbol{y}$进行标准化后再进行余弦相似度计算。皮尔逊相关系数用于计算相似性时有以下问题：
\begin{itemize}
	\item 没有考虑序列的长短。例如两个用户交互的物品的交集可能会比较大或较小，通常交集较大的情况下更可靠，但是交集更小时计算出的皮尔逊系数可能会更大
	\item 若序列长度为1时，根据定义则无法计算皮尔逊系数
	\item 若序列中的值都相同时也无法计算皮尔逊系数，因为方差为0
\end{itemize}


\paragraph{余弦相似度}
两个物品/用户A，B的向量表示为$\boldsymbol{V}_A, \boldsymbol{V}_B$，则余弦相似度为：
$$
sim(A, B) = \frac{\boldsymbol{V}_A \cdot \boldsymbol{V}_B}{||\boldsymbol{V}_A||_2 \times ||\boldsymbol{V}_B||_2}
$$

\paragraph{Jaccard系数}
两个物品/用户A，B的向量表示为$\boldsymbol{V}_A, \boldsymbol{V}_B$，则Jaccard相似度为：
$$
sim(A, B) = \frac{\boldsymbol{V}_A \cdot \boldsymbol{V}_B}{||\boldsymbol{V}_A||_2 + ||\boldsymbol{V}_B||_2 - \boldsymbol{V}_A \cdot \boldsymbol{V}_B}
$$







\subsection{推荐中要注意的点}
\begin{myitemize}
	\item 长尾效应：位于长尾位置的曝光率低的项目产生的利润不低于只销售曝光率高的项目的利润。注意对长尾物品的推荐效果，热门物品的推荐较长尾物品更容易，在评价算法效果时要注意对长尾物品的推荐效果
	\item 用户经常购买的物品并不一定能体现用户的偏好，如很多人都会经常买卫生纸，但这并不能体现用户很喜欢卫生纸，卫生纸作为热门物品反而并不能体现用户的偏好。不同的物品对用户的偏好的贡献是不一样的 --- \textbf{user-aware}
	\item 使用用户行为数据来预测某个用户对某个物品的评分时，要注意历史行为中的物品起的作用可能是不同的\cite{he2018nais}。如预测我会不会买iphone时，可能与我过去买的是什么手机有关 --- \textbf{target item-aware}
	\item 如何对待用户没有交互过的物品？
\end{myitemize}

\subsection{常用指标}
此处介绍的指标不涉及具体的计算公式，在不同的场景下有不同的具体定义，计算自然也相应而变。
\paragraph{覆盖率}覆盖率用来描述一个推荐系统对长尾内容或商品的发掘能力。关于覆盖率的定义，最简单的理解是推荐系统能够推荐出来的物品，占平台中全部物品的比例。

\paragraph{多样性}用户的兴趣是非常广泛的，在一个视频应用中，用户可能既喜欢看烧脑电影，也喜欢看动作大片。那么，为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性。想提升推荐系统的多样性，就需要在较大的时间跨度上去识别和理解用户的兴趣。

\paragraph{新颖性}新颖，指给用户推荐那些他们以前没有听说过的内容或商品，例如在视频应用中应该尽可能多地向用户推荐他们没有看过的电影。而考虑到很多用户在某个应用中的使用粘性可能并不高，例如一个用户可能同时是多个视频应用的用户，所以仅仅依靠用户在自己系统中的行为记录来保证推荐的新颖性是不够的。

除此之外比较简单方法是基于内容或商品的平均流行度去进行推荐，因为越不热门的东西越可能让用户觉得新颖。

不过，向用户推荐不流行的内容或商品，其实是牺牲了一定的推荐精度的，所以我们需要权衡该指标与其它指标之间的平衡——这不仅在于技术层面的考量，可能也在于商业层面的考量。

\paragraph{惊喜度}如果推荐结果和用户的历史兴趣不相似，但却能够让用户觉得满意，那么就可以说推荐结果的惊喜度很高。想要兼顾推荐系统的惊喜度并不是一件容易的事情，因为这意味着需要降低推荐结果和用户历史兴趣的相似度，所以可能会对预测准确度带来一定的挑战。

但毫无疑问，用户需要惊喜，这会极大提升用户的满意度和使用体验，所以推荐系统对惊喜度的追求只会不断提高，且还需要在不影响预测准确度的前提下来实现。过于关注准确率会导致推荐结果的惊喜度不高。


\subsection{用户画像}

\subsection{电商推荐}