\subsection{基本概念}

\subsubsection{历史背景}
\paragraph{Motivation}互联网的发展，人们接受的信息越来越多，从信息稀缺时代逐渐过渡到了信息爆炸时代。面对数据的海洋，我们越来越希望我们感兴趣的信息能够直接呈现在我们面前。\tbc{red}{把用户想要的信息推荐给用户} --- 推荐系统的宗旨。

\paragraph{发展过程}：
\begin{itemize}
	\item 1994年，明尼苏达大学GroupLens研究组推出第一个自动化推荐系统GroupLens，提出将协同过滤作为推荐系统的重要技术
	\item 1995年，卡耐基梅隆大学的Robert Armstrong等人提出个性化导航系统Web Watcher；斯坦福大学的Marko Balabanovic等人退出了个性化推荐系统LIRA
	\item 1997年，Resnick等人首次提出Recommender System一词
 	\item 1998年，Amazon上线了基于物品的协同过滤算法，并在千万级用户和百万计商品的规模上进行了应用。Amazon于2003年发表论文\cite{linden2003amazon.com}公布了基于物品的协同过滤算法
	\item 2001年，IBM在其电子商务平台Websphere中增加个性化功能
	\item 2003年，Google开创AdWords盈利模式，通过用户的广告词来提供相关的广告。2007年Google为AdWords添加个性化元素，通过对用户一段时间内的搜索历史进行记录和分析，以便更精准呈现广告
	\item 2006年，Netflix宣布一项竞赛，任何人只要能将其现有的电影推荐算法Cinematch的预测准确度提高10\%就能获得100万美金
	\item 2007年，Yahoo提出SmartAds广告方案，通过分析用户信息以及用户搜索、浏览行为为用户呈现个性化广告
	\item 2007年，第一届ACM推荐系统大会举行
	\item 2015年，Facebook在其官网公布了其推荐系统原理、性能及使用情况（\href{https://engineering.fb.com/2015/06/02/core-data/recommending-items-to-more-than-a-billion-people/}{Recommending items to more than a billion people}），相关论文\cite{he2014practical}
	\item 2016年，YouTube发表论文\cite{covington2016deep}介绍Youtube如何向用户推荐个性化的视频
	\item 2016年。，Google发表论文\cite{cheng2016wide}介绍App商店中的推荐系统，即Wide\&Deep 模型
\end{itemize}

形式上来看，推荐系统的任务是这样的：给定一个输入，从数据集中搜索出一系列数据对象，并排序后输出。

输入通常是关于某个用户的表示，可以是该用户的特征、向量化的表征等，除此之外用户的行为数据，如用户的浏览记录、搜索记录、与商品的交互数据、用户的一些动态变化的数据等都可以与用户特征一起作为输入，而待搜索的数据集中通常是商品的数据，如商品的特征等，基于以上丰富的信息，将输入的信息与数据集中对象进行匹配，给出推荐的顺序。

乍一看，这和搜索很像。其实这么说也没错，都是一个\tbc{red}{Learning To Rank}的任务。其实很多领域研究的问题都很相似，通过进一步的抽象可以看作是同一个问题。但随着研究的深入，为了在一个问题上取得更好的效果，会相应地结合该领域地特点，如领域内特有的信息、领域内特有的数据形式等。因此，虽然问题之间有重叠，但为了做得更好，除了基础的方法，还需要更深入地挖掘领域地特点！例如，在推荐系统中，用户的需求和兴趣是隐含的（隐含在历史数据中，可能用户都不知道自己喜欢什么），而搜索中搜索语句是显式的（用户需求是明确的）。

\paragraph{推荐系统主要元素}
\begin{itemize}
	\item 物品集合：被推荐的物品或内容
	\item 用户：用户的基本信息，如基本信息、行为信息、兴趣爱好等
	\item 场景：用户所处的环境，如网络环境、所处位置等
	\item 推荐引擎：根据用户对物品的偏好与用户的画像数据进行拟合，学习什么样的用户会喜欢什么样的物品。引擎包含以下重要模块：
	\begin{itemize}
		\item 召回模块：根据用户和场景特征，从整个物品数据集（上百万物品）中挑选用户可能感兴趣的物品，\textbf{挑选出一个较小的候选集}（几百至几千）。召回模块中，通常使用简单的特征进行快速查询，比如用户最近点击的物品的相似物品、根据用户兴趣召回物品等。常用的算法：Word2vec、LDA、LSTM、ItemCF、UserCF、DNN等
		\item 排序模块：针对召回模块找到的\textbf{候选集进行精排}，得到用户对候选物品集的评分。常用的算法：LR、FM、XGBoost、GBDT+LR、Wide\&Deep、FNN、PNN、DeepFM、NFM、DIN等
		\item 后排模块：得到用户对候选集的评分后，可以根据一些规则对排序进行调整，如运营干预、优先级调权等
	\end{itemize}
	\item 推荐结果集：推荐结果，或推荐结果的有序排列
\end{itemize}

\subsubsection{共现矩阵}
显然，共现矩阵是一种矩阵，\textbf{关键是它描述了一种什么事实}？$M, N(|M| = m, |N| = 2)$表示两个相同或者不同的集合，共现矩阵可以用于表达两个集合笛卡尔乘积的元素对的某种关系，$(m_i, n_j)$间的这种关系可以用共现矩阵的元素$CM_{ij}$表示。

在具体的应用场景中，
\begin{itemize}
	\item 推荐系统：$M$表示用户集，$N$表示商品集，$CM_{ij}$表示用户$m_i$对$n_j$的喜爱程度（如评分）、是否点赞、是否分享等
	\item 自然语言处理：$M = N$表示词汇表，$CM_{ij}$表示词$m_i$与词$m_j$出现在同一个句子中的次数
	\item 社交网络：$M=N$表示作者集合，$CM_{ij}$表示$m_i$与$m_j$间存在某种关系，如朋友关系、合作关系等
\end{itemize}
共现矩阵是两个集合的元素间关系的一个很直白的表达。正是因为直白，共现矩阵通常很稀疏，空间需求大。

\subsubsection{召回方法分类}
召回即从海量的数据集中找出尽可能包含真实结果的候选集。常见的分类：
\begin{itemize}
	\item 行为相似召回：通过用户与物品的交互行为，发现行为指向的物品的相似物品
	\item 相似用户召回：通过用户画像和用户行为等，计算用户之间的相似性，根据相似用户的行为进行召回物品
	\item 内容相似召回：通过对物品内容进行分析，得到物品之间的相似性，根据与用户产生交互的物品来召回
\end{itemize}


\subsubsection{常用相似度计算方法}
\paragraph{同现相似度}
物品A和物品B的同现相似度：
$$
w_{A,B} = \frac{|N(A) \cap N(B)|}{|N(A)|}
$$
其中，$A(A), N(B)$分别表示喜欢A和B的用户集合。但是这种相似度有个问题，当B是热门物品时，喜欢A的用户中可能绝大部分也会喜欢B，那么$w_{A,B}$就会接近于1，即任何物品与热门物品的相似度都会接近于1。除此之外，还有个问题，这个相似度不是对称的，即$w_{A,B} \neg w_{B,A}$，这看起来是有点不合理的，因此，其改进如下：
$$
w_{A,B} = \frac{|N(A) \cap N(B)|}{\sqrt{|N(A)| \cdot |N(B)|}}
$$

\paragraph{欧几里得距离}
众所周知，欧氏距离是欧氏空间中两点之间的距离。两个物品A，B的向量表示为$\boldsymbol{V}_A, \boldsymbol{V}_B$，则欧式距离为：
$$
d(A, B) = ||\boldsymbol{V}_A - \boldsymbol{V}_B||_2
$$
以欧式距离计算A，B间相似性时可如下计算：
$$
sim(A, B) = \frac{1}{1 + d(A, B)}
$$
或许还有其他的形式，例如：
$$
sim(A, B) = e^{-d(A, B)}
$$

\paragraph{皮尔逊相关系数}
介于-1和1之间，它度量两个序列（可以是用户对物品的偏好/评分序列）之间的线性相关程度。它度量数字一起按比例改变的倾向性，也就是说两个数列中的数字存在一个大致的线性关系。当该倾向性强时，相关值趋于1。当相关性很弱时，相关值趋于0。在负相关的情况下一个序列的值很高而另一个序列的值低---相关趋势趋于-1。

使用皮尔逊相关系数计算用户/物品相似度时，通常取共现矩阵中的行（用户对各个物品的偏好）或列（各个用户对一个物品的偏好）作为数列来计算皮尔逊相关系数。两个物品/用户A，B的向量表示为$\boldsymbol{x}, \boldsymbol{y}$，则皮尔逊相关系数为：
$$
r_{\boldsymbol{xy}} = \frac{\sum_i (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_i (x_i - \bar{x})^2} \sqrt{\sum_i (y_i - \bar{y})^2}}
$$
其实，仔细一看，皮尔逊相关系数和余弦相似度很像，对$\boldsymbol{x}, \boldsymbol{y}$进行标准化后再进行余弦相似度计算。皮尔逊相关系数用于计算相似性时有以下问题：
\begin{itemize}
	\item 没有考虑序列的长短。例如两个用户交互的物品的交集可能会比较大或较小，通常交集较大的情况下更可靠，但是交集更小时计算出的皮尔逊系数可能会更大
	\item 若序列长度为1时，根据定义则无法计算皮尔逊系数
	\item 若序列中的值都相同时也无法计算皮尔逊系数，因为方差为0
\end{itemize}


\paragraph{余弦相似度}
两个物品/用户A，B的向量表示为$\boldsymbol{V}_A, \boldsymbol{V}_B$，则余弦相似度为：
$$
sim(A, B) = \frac{\boldsymbol{V}_A \cdot \boldsymbol{V}_B}{||\boldsymbol{V}_A||_2 \times ||\boldsymbol{V}_B||_2}
$$

\paragraph{Jaccard系数}
两个物品/用户A，B的向量表示为$\boldsymbol{V}_A, \boldsymbol{V}_B$，则Jaccard相似度为：
$$
sim(A, B) = \frac{\boldsymbol{V}_A \cdot \boldsymbol{V}_B}{||\boldsymbol{V}_A||_2 + ||\boldsymbol{V}_B||_2 - \boldsymbol{V}_A \cdot \boldsymbol{V}_B}
$$

\subsubsection{基于人口统计学的推荐}
特征相似的人喜欢的东西应该也类似。根据\textbf{用户画像}（以用户的基本信息作为相似度计算的基础），找出与目标用户相似的用户，将相似用户喜欢的物品推荐给目标用户。这种方法需要构建用户画像。
\paragraph{优点}
\begin{itemize}
	\item 不涉及当前用户的历史喜好，所以解决了“\textbf{用户冷启动}”问题
	\item 不依赖于物品本身的数据，故而无论这个物品是“书籍”、“音乐”还是“短视频”都可以使用，即它是领域独立的
\end{itemize}

\paragraph{缺点}
\begin{itemize}
	\item 用户画像所需要的有些数据难以获取
	\item 以人口统计信息计算相似用户不可靠。特别是“书籍”“音乐”这种涉及到个人喜好的商品，单用这种方法更是难以达到很好的效果
\end{itemize}

\subsubsection{基于内容的推荐}
把用户可能喜欢的物品类型进行推荐，即要找到相似的物品。需要构建物品的特征，如对物品进行标签化。
\paragraph{优点}
\begin{itemize}
	\item 不存在稀疏性和“\textbf{项目冷启动}”问题
	\item 简单有效，推荐结果具有可解释性，不需要领域知识
	\item 基于物品本身特征推荐，不存在过度推荐热门的问题
	\item \textbf{解决了基于人口统计学对个人兴趣建模的缺失}，能够很好的建模用户的喜好，实现更精确的推荐
\end{itemize}

\paragraph{缺点}
\begin{itemize}
	\item 推荐的结果\textbf{没有新颖性}
	\item 由于需要基于用户的兴趣偏好进行推荐，故而存在“\textbf{用户冷启动}”问题
	\item 该方法受推荐对象特征提取能力的限制。由于是根据物品相似度进行推荐，故而，物品特征构建模型的完善和全面决定了最后推荐的质量，然而像图像、音频等这种类型的特征难以提取
\end{itemize}

\subsubsection{基于协同过滤的推荐}
Collaborative Filtering，通过群体的行为来寻找相似性（用户或物品的相似性），通过该相似性来做推荐。协同过滤算法可以分为以下几类：
\paragraph{基于用户的协同过滤}
User-based CF（UserCF），根据用户对物品的偏好，发现与当前用户口味和偏好相似的“邻居”用户群，并推荐近邻所偏好的物品。与基于人口统计学的推荐的联系与区别：
\begin{itemize}
	\item 都是基于相似用户来推荐
	\item 不同之处在于如何计算用户相似度：基于人口统计学只考虑用户本身的特征，而UserCF是在用户的历史偏好的数据上计算用户的相似度，它的基本假设是，喜欢类似物品的用户可能有相同或者相似的偏好
\end{itemize}
特点：
\begin{itemize}
	\item 适用于用户数较小的场景
	\item 适用于时效性较强（即物品变化频繁），用户个性化兴趣不太明显的领域，如新闻推荐
	\item 在新用户对很少的物品产生行为后，不能立即对它进行个性化推荐，因为用户相似度表示每隔一段时间离线计算的，故而存在“用户冷启动”问题
	\item 新物品上线后一段时间，一旦有用户对物品产生行为，就可以将新物品推荐给和对它产生行为的用户兴趣相似的其他用户，故而解决了“项目冷启动”问题
	\item 解释性较差，因为计算得到的相似用户可能并不是真的相似，并不能真的反映用户的兴趣。；例如，用户都买了卫生纸、水杯等日常用品并不能表示用户之间相似，但如果都买了键盘、屏幕等，则能较可靠的推断用户是相似的，因此在计算用户相似度时要注意这种大家都会关注的“热门物品”，大家都选择热门物品并不能体现用户的真实兴趣（可以依据社交网络来防止相似用户并不相似）
\end{itemize}

\paragraph{基于物品的协同过滤}
Item-based CF（ItemCF），基于用户对物品的偏好，发现物品和物品之间的相似度，然后根据用户的历史偏好信息，将类似的物品推荐给用户。与基于内容的推荐的联系与区别：
\begin{itemize}
	\item 都是基于相似物品进行推荐
	\item 不同之处在于如何计算物品相似度：ItemCF是根据用户历史的偏好（如共现矩阵）推断，而基于内容的推荐是基于物品本身的属性特征
\end{itemize}
特点：
\begin{itemize}
	\item 适用于物品数明显小于用户数的场合，如果物品很多，计算物品的相似度矩阵的代价就会很大
	\item 适合于长尾物品丰富，用户个性化需求强烈的领域，如电商网站
	\item 用户有新行为，一定会导致推荐结果的实时变化
	\item 新用户只要对一个物品产生行为，就可以给它推荐和该物品相关的其它物品，故而解决了“用户冷启动”问题
	\item 不能在不离线更新物品相似度的情况下将新的物品推荐给用户，故而存在“项目冷启动”问题
	\item 有较强的解释性，因为是依据用户历史偏好的物品来推荐
\end{itemize}


\paragraph{基于模型的协同过滤}
Model-based CF（ModelCF）。基本思想：用户具有一定的特征，决定着他的偏好选择；物品具有一定的特征，影响着用户需是否选择它；用户之所以选择某一个商品，是因为用户特征与物品特征相互匹配。ModelCF基于样本的用户偏好信息，训练一个推荐模型，然后根据实时的用户喜好的信息进行预测，计算推荐。

参考：\href{https://www.cnblogs.com/shengyang17/p/11516532.html}{基于协同过滤的推荐算法}、\href{https://zhuanlan.zhihu.com/p/108759393}{推荐系统——经典算法（基于内容、协同过滤、混合等）}。

\subsubsection{推荐中要注意的点}
\begin{myitemize}
	\item 长尾效应：位于长尾位置的曝光率低的项目产生的利润不低于只销售曝光率高的项目的利润。注意对长尾物品的推荐效果，热门物品的推荐较长尾物品更容易，在评价算法效果时要注意对长尾物品的推荐效果
	\item 用户经常购买的物品并不一定能体现用户的偏好，如很多人都会经常买卫生纸，但这并不能体现用户很喜欢卫生纸，卫生纸作为热门物品反而并不能体现用户的偏好。不同的物品对用户的偏好的贡献是不一样的 --- \textbf{user-aware}
	\item 使用用户行为数据来预测某个用户对某个物品的评分时，要注意历史行为中的物品起的作用可能是不同的\cite{he2018nais}。如预测我会不会买iphone时，可能与我过去买的是什么手机有关 --- \textbf{target item-aware}
	\item 如何对待用户没有交互过的物品？
\end{myitemize}

\subsubsection{常用指标}
此处介绍的指标不涉及具体的计算公式，在不同的场景下有不同的具体定义，计算自然也相应而变。
\paragraph{覆盖率}覆盖率用来描述一个推荐系统对长尾内容或商品的发掘能力。关于覆盖率的定义，最简单的理解是推荐系统能够推荐出来的物品，占平台中全部物品的比例。

\paragraph{多样性}用户的兴趣是非常广泛的，在一个视频应用中，用户可能既喜欢看烧脑电影，也喜欢看动作大片。那么，为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性。想提升推荐系统的多样性，就需要在较大的时间跨度上去识别和理解用户的兴趣。

\paragraph{新颖性}新颖，指给用户推荐那些他们以前没有听说过的内容或商品，例如在视频应用中应该尽可能多地向用户推荐他们没有看过的电影。而考虑到很多用户在某个应用中的使用粘性可能并不高，例如一个用户可能同时是多个视频应用的用户，所以仅仅依靠用户在自己系统中的行为记录来保证推荐的新颖性是不够的。

除此之外比较简单方法是基于内容或商品的平均流行度去进行推荐，因为越不热门的东西越可能让用户觉得新颖。

不过，向用户推荐不流行的内容或商品，其实是牺牲了一定的推荐精度的，所以我们需要权衡该指标与其它指标之间的平衡——这不仅在于技术层面的考量，可能也在于商业层面的考量。

\paragraph{惊喜度}如果推荐结果和用户的历史兴趣不相似，但却能够让用户觉得满意，那么就可以说推荐结果的惊喜度很高。想要兼顾推荐系统的惊喜度并不是一件容易的事情，因为这意味着需要降低推荐结果和用户历史兴趣的相似度，所以可能会对预测准确度带来一定的挑战。

但毫无疑问，用户需要惊喜，这会极大提升用户的满意度和使用体验，所以推荐系统对惊喜度的追求只会不断提高，且还需要在不影响预测准确度的前提下来实现。过于关注准确率会导致推荐结果的惊喜度不高。


\subsection{经典算法}
\subsubsection{FM}
Factorization Machine，因子分解机。

\subsubsection{FFM}
Field-aware Factorization Machine，